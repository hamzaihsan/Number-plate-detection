{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-31T09:24:41.751281Z","iopub.execute_input":"2023-07-31T09:24:41.751714Z","iopub.status.idle":"2023-07-31T09:24:41.765341Z","shell.execute_reply.started":"2023-07-31T09:24:41.751680Z","shell.execute_reply":"2023-07-31T09:24:41.763926Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"/kaggle/input/number/images/N40.jpeg\n/kaggle/input/number/images/N30.xml\n/kaggle/input/number/images/N42.xml\n/kaggle/input/number/images/N21.xml\n/kaggle/input/number/images/N19.jpeg\n/kaggle/input/number/images/N25.xml\n/kaggle/input/number/images/N32.xml\n/kaggle/input/number/images/N17.jpeg\n/kaggle/input/number/images/N1.xml\n/kaggle/input/number/images/N14.xml\n/kaggle/input/number/images/N24.xml\n/kaggle/input/number/images/N36.xml\n/kaggle/input/number/images/N24.jpeg\n/kaggle/input/number/images/N38.jpeg\n/kaggle/input/number/images/N15.jpeg\n/kaggle/input/number/images/N18.xml\n/kaggle/input/number/images/N4.xml\n/kaggle/input/number/images/N31.xml\n/kaggle/input/number/images/N33.jpeg\n/kaggle/input/number/images/N25.jpeg\n/kaggle/input/number/images/N30.jpeg\n/kaggle/input/number/images/N6.jpeg\n/kaggle/input/number/images/N5.xml\n/kaggle/input/number/images/N37.xml\n/kaggle/input/number/images/N15.xml\n/kaggle/input/number/images/N34.xml\n/kaggle/input/number/images/N5.jpeg\n/kaggle/input/number/images/N42.jpeg\n/kaggle/input/number/images/N8.jpeg\n/kaggle/input/number/images/N28.xml\n/kaggle/input/number/images/N1.jpeg\n/kaggle/input/number/images/N31.jpeg\n/kaggle/input/number/images/N2.xml\n/kaggle/input/number/images/N16.xml\n/kaggle/input/number/images/N36.jpeg\n/kaggle/input/number/images/N38.xml\n/kaggle/input/number/images/N28.jpeg\n/kaggle/input/number/images/N43.jpeg\n/kaggle/input/number/images/N11.xml\n/kaggle/input/number/images/N4.jpeg\n/kaggle/input/number/images/N18.jpeg\n/kaggle/input/number/images/N8.xml\n/kaggle/input/number/images/N11.jpeg\n/kaggle/input/number/images/N35.jpeg\n/kaggle/input/number/images/N27.xml\n/kaggle/input/number/images/N3.xml\n/kaggle/input/number/images/N6.xml\n/kaggle/input/number/images/N14.jpeg\n/kaggle/input/number/images/N20.xml\n/kaggle/input/number/images/N32.jpeg\n/kaggle/input/number/images/N19.xml\n/kaggle/input/number/images/N43.xml\n/kaggle/input/number/images/N27.jpeg\n/kaggle/input/number/images/N9.jpeg\n/kaggle/input/number/images/N37.jpeg\n/kaggle/input/number/images/N40.xml\n/kaggle/input/number/images/N7.jpeg\n/kaggle/input/number/images/N9.xml\n/kaggle/input/number/images/N23.jpeg\n/kaggle/input/number/images/N22.jpeg\n/kaggle/input/number/images/N17.xml\n/kaggle/input/number/images/N35.xml\n/kaggle/input/number/images/N12.xml\n/kaggle/input/number/images/N20.jpeg\n/kaggle/input/number/images/N22.xml\n/kaggle/input/number/images/N12.jpeg\n/kaggle/input/number/images/N3.jpeg\n/kaggle/input/number/images/N16.jpeg\n/kaggle/input/number/images/N7.xml\n/kaggle/input/number/images/N34.jpeg\n/kaggle/input/number/images/N21.jpeg\n/kaggle/input/number/images/N33.xml\n/kaggle/input/number/images/N23.xml\n/kaggle/input/number/images/N2.jpeg\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport tensorflow as tf\nimport pytesseract as pt\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as xet\nfrom glob import glob\nfrom skimage import io\nfrom shutil import copy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.770812Z","iopub.execute_input":"2023-07-31T09:24:41.771286Z","iopub.status.idle":"2023-07-31T09:24:41.780337Z","shell.execute_reply.started":"2023-07-31T09:24:41.771251Z","shell.execute_reply":"2023-07-31T09:24:41.778850Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"path = glob('/kaggle/input/number/images/*.xml')\nlabels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])\nfor filename in path:\n    info = xet.parse(filename)\n    root = info.getroot()\n    member_object = root.find('object')\n    labels_info = member_object.find('bndbox')\n    xmin = int(labels_info.find('xmin').text)\n    xmax = int(labels_info.find('xmax').text)\n    ymin = int(labels_info.find('ymin').text)\n    ymax = int(labels_info.find('ymax').text)\n\n    labels_dict['filepath'].append(filename)\n    labels_dict['xmin'].append(xmin)\n    labels_dict['xmax'].append(xmax)\n    labels_dict['ymin'].append(ymin)\n    labels_dict['ymax'].append(ymax)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.783813Z","iopub.execute_input":"2023-07-31T09:24:41.784302Z","iopub.status.idle":"2023-07-31T09:24:41.831731Z","shell.execute_reply.started":"2023-07-31T09:24:41.784264Z","shell.execute_reply":"2023-07-31T09:24:41.830753Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(labels_dict)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.834608Z","iopub.execute_input":"2023-07-31T09:24:41.835003Z","iopub.status.idle":"2023-07-31T09:24:41.852218Z","shell.execute_reply.started":"2023-07-31T09:24:41.834970Z","shell.execute_reply":"2023-07-31T09:24:41.850887Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"                              filepath  xmin  xmax  ymin  ymax\n0  /kaggle/input/number/images/N30.xml   928  1219   543   606\n1  /kaggle/input/number/images/N42.xml   163   373   253   327\n2  /kaggle/input/number/images/N21.xml   244   403   221   258\n3  /kaggle/input/number/images/N25.xml   132   235   169   193\n4  /kaggle/input/number/images/N32.xml   360   500   171   206","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>xmin</th>\n      <th>xmax</th>\n      <th>ymin</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/number/images/N30.xml</td>\n      <td>928</td>\n      <td>1219</td>\n      <td>543</td>\n      <td>606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/number/images/N42.xml</td>\n      <td>163</td>\n      <td>373</td>\n      <td>253</td>\n      <td>327</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/number/images/N21.xml</td>\n      <td>244</td>\n      <td>403</td>\n      <td>221</td>\n      <td>258</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/number/images/N25.xml</td>\n      <td>132</td>\n      <td>235</td>\n      <td>169</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/number/images/N32.xml</td>\n      <td>360</td>\n      <td>500</td>\n      <td>171</td>\n      <td>206</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"image_path = list(df['filepath'].apply(getFilename))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.853742Z","iopub.execute_input":"2023-07-31T09:24:41.854580Z","iopub.status.idle":"2023-07-31T09:24:41.899104Z","shell.execute_reply.started":"2023-07-31T09:24:41.854535Z","shell.execute_reply":"2023-07-31T09:24:41.897759Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"\ndef getFilename(filename):\n    filename_image = xet.parse(filename).getroot().find('filename').text\n    filepath_image = os.path.join('/kaggle/input/number/images',filename_image)\n    return filepath_image\ngetFilename(filename)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.901716Z","iopub.execute_input":"2023-07-31T09:24:41.902266Z","iopub.status.idle":"2023-07-31T09:24:41.912706Z","shell.execute_reply.started":"2023-07-31T09:24:41.902229Z","shell.execute_reply":"2023-07-31T09:24:41.911279Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/number/images/N23.jpeg'"},"metadata":{}}]},{"cell_type":"code","source":"img_arr = cv2.imread(image_path[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.914489Z","iopub.execute_input":"2023-07-31T09:24:41.915640Z","iopub.status.idle":"2023-07-31T09:24:41.953175Z","shell.execute_reply.started":"2023-07-31T09:24:41.915594Z","shell.execute_reply":"2023-07-31T09:24:41.951523Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"labels = df.iloc[:,1:].values\ndata = []\noutput = []\nfor ind in range(len(image_path)):\n    image = image_path[ind]\n    img_arr = cv2.imread(image)\n    img_arr=np.array(img_arr)\n    h,w,d = img_arr.shape\n    # Prepprocesing\n    load_image = load_img(image,target_size=(224,224))\n    load_image_arr = img_to_array(load_image)\n    norm_load_image_arr = load_image_arr/255.0 # Normalization\n    # Normalization to labels\n    xmin,xmax,ymin,ymax = labels[ind]\n    nxmin,nxmax = xmin/w,xmax/w\n    nymin,nymax = ymin/h,ymax/h\n    label_norm = (nxmin,nxmax,nymin,nymax) # Normalized output\n    # Append\n    data.append(norm_load_image_arr)\n    output.append(label_norm)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:41.954557Z","iopub.execute_input":"2023-07-31T09:24:41.955241Z","iopub.status.idle":"2023-07-31T09:24:43.600404Z","shell.execute_reply.started":"2023-07-31T09:24:41.955201Z","shell.execute_reply":"2023-07-31T09:24:43.599326Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"X = np.array(data,dtype=np.float32)\ny = np.array(output,dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:43.602149Z","iopub.execute_input":"2023-07-31T09:24:43.603046Z","iopub.status.idle":"2023-07-31T09:24:43.615391Z","shell.execute_reply.started":"2023-07-31T09:24:43.602996Z","shell.execute_reply":"2023-07-31T09:24:43.614316Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=0)\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:24:43.616901Z","iopub.execute_input":"2023-07-31T09:24:43.617943Z","iopub.status.idle":"2023-07-31T09:24:43.634558Z","shell.execute_reply.started":"2023-07-31T09:24:43.617889Z","shell.execute_reply":"2023-07-31T09:24:43.632953Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"((29, 224, 224, 3), (8, 224, 224, 3), (29, 4), (8, 4))"},"metadata":{}}]},{"cell_type":"code","source":"model=VGG16(include_top=False,input_shape = (224,224,3),weights='imagenet')\nmodel.trainable = False\nflatten = Flatten()(model.output)\nx= Dense(512 , activation = \"relu\")(flatten)\nx= Dense(256 , activation = \"relu\")(x)\nx= Dense(128 , activation = \"relu\")(x)\nx= Dense(64 , activation = \"relu\")(x)\nx= Dense(32 , activation = \"relu\")(x)\nbbox = Dense(4)(x)\nfinal=Model(inputs = model.input , outputs = bbox)\nfinal.compile(loss='categorical_crossentropy', optimizer='adam')\nfinal.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:28:53.200804Z","iopub.execute_input":"2023-07-31T09:28:53.201264Z","iopub.status.idle":"2023-07-31T09:28:53.909736Z","shell.execute_reply.started":"2023-07-31T09:28:53.201228Z","shell.execute_reply":"2023-07-31T09:28:53.908502Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"Model: \"model_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_22 (InputLayer)       [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten_11 (Flatten)        (None, 25088)             0         \n                                                                 \n dense_39 (Dense)            (None, 512)               12845568  \n                                                                 \n dense_40 (Dense)            (None, 256)               131328    \n                                                                 \n dense_41 (Dense)            (None, 128)               32896     \n                                                                 \n dense_42 (Dense)            (None, 64)                8256      \n                                                                 \n dense_43 (Dense)            (None, 32)                2080      \n                                                                 \n dense_44 (Dense)            (None, 4)                 132       \n                                                                 \n=================================================================\nTotal params: 27,734,948\nTrainable params: 13,020,260\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"final.fit(x_train,y_train,batch_size=8,epochs=100)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T09:29:04.742459Z","iopub.execute_input":"2023-07-31T09:29:04.742899Z","iopub.status.idle":"2023-07-31T09:31:28.467708Z","shell.execute_reply.started":"2023-07-31T09:29:04.742862Z","shell.execute_reply":"2023-07-31T09:31:28.466434Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Epoch 1/10\n4/4 [==============================] - 10s 2s/step - loss: 3.6386\nEpoch 2/10\n4/4 [==============================] - 8s 2s/step - loss: 3.0572\nEpoch 3/10\n4/4 [==============================] - 9s 2s/step - loss: 3.0106\nEpoch 4/10\n4/4 [==============================] - 8s 2s/step - loss: 3.0082\nEpoch 5/10\n4/4 [==============================] - 8s 2s/step - loss: 3.0041\nEpoch 6/10\n4/4 [==============================] - 8s 2s/step - loss: 3.0001\nEpoch 7/10\n4/4 [==============================] - 9s 2s/step - loss: 2.9972\nEpoch 8/10\n4/4 [==============================] - 8s 2s/step - loss: 2.9955\nEpoch 9/10\n4/4 [==============================] - 8s 2s/step - loss: 2.9922\nEpoch 10/10\n4/4 [==============================] - 8s 2s/step - loss: 2.9808\n","output_type":"stream"},{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7d16dc1942e0>"},"metadata":{}}]}]}